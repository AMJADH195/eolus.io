#!/bin/bash

# Another script in the GRIBLoader family.
# This one retrieves the NAEFS NDGD data.
#
# Thomas Horner | thomas@14ersForecast.net


# Looks through the remote directory of GRIB files
# to see what the last completed model run was.
function check_if_data_exists {
	FILE="http://nomads.ncep.noaa.gov/pub/data/nccf/com/gens/prod/naefs.$1/$2/ndgd_gb2/naefs.t$2z.geavg.f384.conus_ext_2p5.grib2"
	echo "Endpoint: $FILE"

	if curl --output /dev/null --silent --head --fail "$FILE"; then
		echo "------ It exists. ------"
		update_data $1 $2
	else
		echo "It doesn't exist."
	fi
}

# Sets the correct filename to be downloaded, then retrieves the
# GRIB subet from NCEP NOMADS, converts and reprojects it to TIF.
function download_and_convert {
	# $1 = model var (TMP, etc.); $2 = model level; $3 = date; $4 = filename; $5 = forecast hour; $6 = label; $7 = output filename; $8 = output directory
	echo ""
	echo "-----------------------------"
	echo "Downloading and converting..."
	echo "Parameter: $6 || Hour: $5"
	
	# Set some filenames
	URL="http://nomads.ncep.noaa.gov/cgi-bin/filter_naefsbc_ndgd.pl?file="
	URL+=$4
	URL+="&"
	URL+=$2
	URL+="&"
	URL+=$1
	URL+="&subregion=&leftlon=250&rightlon=258&toplat=42&bottomlat=36&dir=%2Fnaefs."
	URL+=$3
    URL+="%2F"
    URL+=$9
    URL+="%2Fndgd_gb2"

	SHORTNAME=$8
	SHORTNAME+=$7
	SHORTNAME+=$5

	OUTPUTFILE=$SHORTNAME
	OUTPUTFILE+=".grib2"

	TIFF=$8
	TIFF+=$7
	TIFF+="_"
	TIFF+=`date -d "$3 $9 +$5 hour" +%Y%m%dT%H` 
	TIFF+="0000000Z.tif"
	
	# Download the GRIB subset from NCEP NOMADS
	echo "Downloading as $OUTPUTFILE."
	wget $URL -O $OUTPUTFILE -nv
	
	# GDAL helpfully reprojects and converts the filetype to TIF
	# We're going to use the EPSG:4326 projection
	echo "Reprojecting and converting, saving as $TIFF."
	gdalwarp $OUTPUTFILE $TIFF -t_srs EPSG:4326 -overwrite -multi -wo SOURCE_EXTRA=1000 --config CENTER_LONG 0 -co TILED=YES -co COMPRESS=NONE

	# Delete the GRIB
	rm $OUTPUTFILE
	echo "... Done."
	echo "-----------------------------"
	echo ""
}

# Loops through the 0-120 hour GFS forecast and grabs the file
# for each specified parameter type (temp, wind, precip, etc.)
function download_files {
	echo "Downloading files."
	for i in `seq -f %03g 000 240`;
        do
		FILENAME="naefs.t"
		FILENAME+=$1
		FILENAME+="z.geavg.f"
		FILENAME+=$i
        FILENAME+=".conus_ext_2p5.grib2"
		download_and_convert "var_DPT=on" "lev_2_m_above_ground=on" $2 $FILENAME $i "Dewpoint" "Dewpoint" "/wxdata/naefs/dpt/" $1
		download_and_convert "var_PRES=on" "all_lev=on" $2 $FILENAME $i "Pressure" "Pressure" "/wxdata/naefs/pres/" $1
		download_and_convert "var_RH=on" "lev_2_m_above_ground=on" $2 $FILENAME $i "Relative Humidity" "RelativeHumidity" "/wxdata/naefs/rh/" $1
		download_and_convert "var_TMAX=on" "lev_2_m_above_ground=on" $2 $FILENAME $i "Maximum Temperature" "TempMax" "/wxdata/naefs/tmax/" $1
		download_and_convert "var_TMIN=on" "lev_2_m_above_ground=on" $2 $FILENAME $i "Minimum Temperature" "TempMin" "/wxdata/naefs/tmin/" $1
        download_and_convert "var_TMP=on" "lev_2_m_above_ground=on" $2 $FILENAME $i "Surface Temperature" "SurfaceTemp" "/wxdata/naefs/tmp/" $1
        download_and_convert "var_UGRD=on" "lev_10_m_above_ground=on" $2 $FILENAME $i "Wind U Component" "SurfaceWindU" "/wxdata/naefs/ugrd/" $1
        download_and_convert "var_VGRD=on" "lev_10_m_above_ground=on" $2 $FILENAME $i "Wind V Component" "SurfaceWindV" "/wxdata/naefs/vgrd/" $1
	done
}

# Checks to see if there's new data that needs to be downloaded.
# Keeps track of the last date of the model run with a local file
# 'naefsLastUpdated.txt' which just stores the date and time of the model run.
# If the script runs successfully it overwrites this date and time with the latest.
function update_data {
	echo "---------------------"
	echo "Update Data function."
	echo "CHECKDATE: $1"
	echo "CHECKTIME: $2"
	# check if we've already updated this
	read -r lastupdated<"naefsLastUpdated.txt"
	echo "Last updated: $lastupdated"	

	if [ $lastupdated = $1$2 ]; then
		echo "Nevermind, we've got this data already."
		exit 0
	fi
	
	echo "We need to get the new data."
	download_files $2 $1

	echo "Done, now cleaning up."
	echo "Deleting old files..."

	find /wxdata/ -type f -mtime +1 -name '*.tif' -execdir rm -- '{}' \;

	# Cache the data
	python cacher.py --model naefs

	# Exit script
	echo "$1$2" > naefsLastUpdated.txt
	echo "You're all clear kid, now let's blow this thing and go home."
	exit 0
}	

##### MAIN #####
#set -e

echo "------------------"
echo "WX4Web GRIB Data Loader (NAEFS)"
echo "------------------"
DATE=`date +%Y%m%d`
YEAR=`date +%Y`
MONTH=`date +%m`
DAY=`date +%d`
echo "Initialized date variables."
echo "YEAR: $YEAR"
echo "MONTH: $MONTH"
echo "DAY: $DAY"
echo "------------"

# I can easily imagine a much better way of doing the below
# repetitive tasks...  but whatever.  Since there is considerable
# lag time publishing the models it looks back in time quite a ways.
# Not elegant, but it works.
#
# I didn't really think too much about what time the server actually
# thinks it is.  At least on my test server it uses UTC time
# so the month/day matches that of the model runs.  However
# if your date function is returning local time for some reason
# you may need to look ahead a day to capture the actual UTC date.

CHECKDATE=`date +%Y%m%d`
CHECKTIME="18"
echo "Checking 18Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date +%Y%m%d`
CHECKTIME="12"
echo "Checking 12Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date +%Y%m%d`
CHECKTIME="06"
echo "Checking 06Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date +%Y%m%d`
CHECKTIME="00"
echo "Checking 00Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date -d '-1 day' +%Y%m%d`
CHECKTIME="18"
echo "Checking 18Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date -d '-1 day' +%Y%m%d`
CHECKTIME="12"
echo "Checking 12Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date -d '-1 day' +%Y%m%d`
CHECKTIME="06"
echo "Checking 06Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME

CHECKDATE=`date -d '-1 day' +%Y%m%d`
CHECKTIME="00"
echo "Checking 00Z $CHECKDATE"
check_if_data_exists $CHECKDATE $CHECKTIME
